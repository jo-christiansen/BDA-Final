{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4112be7",
   "metadata": {},
   "source": [
    "# BDA Final - ML for predicting heart diseases / attacks \n",
    "\n",
    "The goal of this mashine learning paper is to reveal hidden / non-obvious features contributing to heart diseases / attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6536cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f486912",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 330) #displaying all of the columns in CDC datasets\n",
    "\n",
    "df_cdc = pd.read_csv('Datasets/BRFSS_2015.csv') #importing the CDC dataset\n",
    "df_kaggle = pd.read_csv('Datasets/heart_disease_indicators(KaeggleImport).csv') #importing kaggles cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compareing kaggles colums to the colunms of the original dataset by the CDC \n",
    "\n",
    "column_names_cdc = []\n",
    "column_names_kaggle = []\n",
    "\n",
    "for col in df_cdc:\n",
    "    column_names_cdc.append(col)\n",
    "\n",
    "print(column_names_cdc)\n",
    "print('\\n')\n",
    "\n",
    "for col in df_kaggle:\n",
    "    column_names_kaggle.append(col)\n",
    "\n",
    "print(column_names_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b61456",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of CDC dataset: {}'.format(df_cdc.shape)) #compareing shapes \n",
    "print('Shape of Kaggle dataset: {}'.format(df_kaggle.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a7e590",
   "metadata": {},
   "source": [
    "### Removing all the columns that contain more than 5% of NaN values and/or are irrelevant for our ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a546c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df_name):\n",
    "    redundant_columns = ['FMONTH','IDATE','IMONTH','IDAY','IYEAR','DISPCODE','SEQNO','_PSU','CTELENUM',\n",
    "                         'PVTRESD1','COLGHOUS','STATERES','CELLFON3','LADULT','NUMADULT','NUMMEN','NUMWOMEN',\n",
    "                         'CTELNUM1','CELLFON2','CADULT','PVTRESD2','CCLGHOUS','CSTATE','LANDLINE','HHADULT',\n",
    "                         'POORHLTH','BPMEDS','ASTHNOW','DIABAGE2','NUMHHOL2','NUMPHON2','CPDEMO1','PREGNANT',\n",
    "                         'SMOKDAY2','STOPSMK2','LASTSMK2','AVEDRNK2','DRNK3GE5','MAXDRNKS','FRUITJU1','FRUIT1',\n",
    "                         'FVBEANS','FVGREEN','FVORANG','VEGETAB1','EXERANY2','EXRACT11','EXEROFT1','EXERHMM1',\n",
    "                         'EXRACT21','EXEROFT2','EXERHMM2','STRENGTH','LMTJOIN3','ARTHDIS2','ARTHSOCL','JOINPAIN',\n",
    "                         'SEATBELT','FLUSHOT6','FLSHTMY2','IMFVPLAC','PNEUVAC3','HIVTST6','HIVTSTD3','WHRTST10',\n",
    "                         'PDIABTST','PREDIAB1','INSULIN','BLDSUGAR','FEETCHK2','DOCTDIAB','CHKHEMO3','FEETCHK',\n",
    "                         'EYEEXAM','DIABEYE','DIABEDU','PAINACT2','QLMENTL2','QLSTRES2','QLHLTH2','CAREGIV1',\n",
    "                         'CRGVREL1','CRGVLNG1','CRGVHRS1','CRGVPRB1','CRGVPERS','CRGVHOUS','CRGVMST2','CRGVEXPT',\n",
    "                         'VIDFCLT2','VIREDIF3','VIREDIF3','VINOCRE2','VIEYEXM2','VIINSUR2','VICTRCT4','VIGLUMA2',\n",
    "                         'VIMACDG2','CIMEMLOS','CDHOUSE','CDASSIST','CDHELP','CDSOCIAL','CDDISCUS','WTCHSALT',\n",
    "                         'LONGWTCH','DRADVISE','ASTHMAGE','ASATTACK','ASERVIST','ASDRVIST','ASRCHKUP','ASACTLIM',\n",
    "                         'ASRCHKUP','ASACTLIM','ASYMPTOM','ASNOSLEP','ASTHMED3','ASINHALR','HAREHAB1','STREHAB1',\n",
    "                         'CVDASPRN','ASPUNSAF','RLIVPAIN','RDUCHART','RDUCSTRK','ARTTODAY','ARTHWGT','ARTHEXER',\n",
    "                         'ARTHEDU','TETANUS', 'HPVADVC2','HPVADSHT','SHINGLE2','HADMAM','HOWLONG','HADPAP2',\n",
    "                         'LASTPAP2','HPVTEST','HPLSTTST','HADHYST2','PROFEXAM','LENGEXAM','BLDSTOOL','LSTBLDS3',\n",
    "                         'HADSIGM3','HADSGCO1','LASTSIG3','PCPSAAD2','PCPSADI1','PCPSARE1','PSATEST1','PSATIME',\n",
    "                         'PCPSARS1','PCDMDECN','SCNTMNY1','SCNTMEL1','SCNTPAID','SCNTWRK1','SCNTLPAD','SCNTLWK1',\n",
    "                         'RCSGENDR','RCSRLTN2','CASTHDX2','CASTHNO2','EMTSUPRT','LSATISFY','ADPLEASR','ADDOWN',\n",
    "                         'ADSLEEP','ADENERGY','ADEAT1','ADFAIL','ADTHINK','ADMOVE','MISTMNT','ADANXEV','EXACTOT1',\n",
    "                         'EXACTOT2','_STSTR','_STRWT','_RAWRAKE','_WT2RAKE','_CRACE1','_CPRACE','_CLLCPWT','_DUALCOR',\n",
    "                         '_CLLCPWT','PADUR2_','METVL11_','METVL21_','ACTIN11_','ACTIN21_','PADUR1_','PAFREQ1_',\n",
    "                         'PAFREQ2_','_MINAC11','_MINAC21','PAMIN11_','PAMIN21_','PA1MIN_','PAVIG11_','PAVIG21_',\n",
    "                         'PA1VIGM_', 'VIPRFVS2', '_FLSHOT6', '_PNEUMO2', 'PCPSADE1', '_LLCPWT', 'SXORIENT', \n",
    "                         'TRNSGNDR', '_CHISPNC'] \n",
    "    df_name = df_name.drop(columns = redundant_columns, axis = 1, inplace = True) \n",
    "    return df_name\n",
    "\n",
    "remove_columns(df_cdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd8107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cdc.isnull().sum().to_string(max_rows=None)) #looking at the NaN values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786fbf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdc['MSCODE'].fillna(7, inplace=True) #MSCODE stood out with 190k NaN values, but the CodeBook tells us that in \n",
    "                                           #--> this case NaN stands for something rather than no answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf0f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdc.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c4f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cdc.shape)\n",
    "df_cdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbf7545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdc.to_csv('NanCleanFinal.csv', sep=\",\", index=False) #for simplicity we'll safe df_cdc in a seperate file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8b03e7",
   "metadata": {},
   "source": [
    "## Working with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a06c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 125)\n",
    "df = pd.read_csv('Datasets/NaNCleanFinal.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46799e06",
   "metadata": {},
   "source": [
    "## Visualizations to better understand the data we are dealing with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d663a13",
   "metadata": {},
   "source": [
    "### Age distribution of the particapants in the survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf013a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to map old values to new values\n",
    "age_map = {1:'18-24', 2:'25-29', 3:'30-34', 4:'35-39', 5:'40-44', 6:'45-49',\n",
    "           7:'50-54', 8:'55-59', 9:'60-64', 10:'65-69', 11:'70-74', 12:'75-79',\n",
    "           13:'80+', 14:'Not known'}\n",
    "\n",
    "# Use the map method to replace the values in the '_AGEG5YR' column\n",
    "df['_AGEG5YR'] = df['_AGEG5YR'].map(age_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd0271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['_AGEG5YR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8), dpi=100) #creating a figur for the histogram\n",
    "\n",
    "# plot to the existing fig, by using ax=ax\n",
    "p = sns.histplot(df._AGEG5YR, stat='percent', discrete=True, shrink=.8,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e0128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = df.value_counts(df['_AGEG5YR']) #counting instances of each range of ages\n",
    "bars = ('60-64','65-69','55-59','50-54','70-74','80+','45-49','75-79',\n",
    "        '40-44','35-39','30-34','25-29','18-24','Not known') #labelling the bars\n",
    "x_pos = np.arange(len(bars))\n",
    " \n",
    "fig, ax = plt.subplots(figsize=(15, 10), dpi=100)\n",
    "    \n",
    "plt.bar(x_pos, height, width=.8, color = ('#1f77b4'), edgecolor = ('#000000')) #plotting and selecting colour\n",
    "\n",
    "plt.title('Distribution of Age groups')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Instances')\n",
    " \n",
    "plt.xticks(x_pos, bars)  #Create names on the x axis\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8951ec52",
   "metadata": {},
   "source": [
    "### Race distribution of the participants of the survey "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5637649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the values for the RACE column to actual races\n",
    "# Define a dictionary to map old values to new values\n",
    "race_map = {1:'White', 2:'Black', 3:'Other race', 4:'Multiracial', 5:'Hispanic', 9:\"Don't know/Refused\"}\n",
    "\n",
    "# Use the map method to replace the values in the '_RACEGR3' column\n",
    "df['_RACEGR3'] = df['_RACEGR3'].map(race_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb03d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['_RACEGR3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f3399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8), dpi=100) #creating a figur for the histogram\n",
    "\n",
    "# plot to the existing fig, by using ax=ax\n",
    "p = sns.histplot(df._RACEGR3, stat='percent', discrete=True, shrink=.8,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = df.value_counts(df['_RACEGR3']) #counting instances of each race\n",
    "bars = ('White','Black','Hispanic','Other Race','Multiracial') #labelling the bars\n",
    "x_pos = np.arange(len(bars))\n",
    " \n",
    "fig, ax = plt.subplots(figsize=(15, 10), dpi=100)\n",
    "    \n",
    "plt.bar(x_pos, height, width=.8, color = ('#1f77b4'), edgecolor = ('#000000')) #plotting and selecting colour\n",
    "\n",
    "plt.title('Distribution of race')\n",
    "plt.xlabel('Race')\n",
    "plt.ylabel('Instances')\n",
    " \n",
    "plt.xticks(x_pos, bars)  #Create names on the x axis\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0185356f",
   "metadata": {},
   "source": [
    "### Creating a sub-dataset for the visualization of percentage of heart attacks/diseases per state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e91e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = df[['_STATE', '_MICHD']] #creating the subset\n",
    "df_map['_MICHD'] = df_map['_MICHD'].replace({2: 0}) #bringing our target value to a binary scale of '0' and '1'\n",
    "df_map._MICHD.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1cf397",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map_usa = df_map.groupby(['_STATE']).sum() #indexing by state\n",
    "df_map_usa['Population'] =  df_map['_STATE'].value_counts() #adding the survey particiapants per state as population\n",
    "df_map_usa['Percentage'] = df_map_usa['_MICHD'] / df_map_usa['Population'] #percentage heart attack per population\n",
    "df_map_usa['Percentage'] = df_map_usa['Percentage'] * 100 \n",
    "df_map_usa['Percentage'] = df_map_usa['Percentage'].round(2) #getting real percentages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36821e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to map state codes to state names\n",
    "state_map = {1: 'Alabama', 2: 'Alaska', 4: 'Arizona', 5: 'Arkansas', 6: 'California',\n",
    "             8: 'Colorado', 9: 'Connecticut', 10: 'Delaware', 11: 'District of Columbia',\n",
    "             12: 'Florida', 13: 'Georgia', 15: 'Hawaii', 16: 'Idaho', 17: 'Illinois',\n",
    "             18: 'Indiana', 19: 'Iowa', 20: 'Kansas', 21: 'Kentucky', 22: 'Louisiana',\n",
    "             23: 'Maine', 24: 'Maryland', 25: 'Massachusetts', 26: 'Michigan',\n",
    "             27: 'Minnesota', 28: 'Mississippi', 29: 'Missouri', 30: 'Montana',\n",
    "             31: 'Nebraska', 32: 'Nevada', 33: 'New Hampshire', 34: 'New Jersey',\n",
    "             35: 'New Mexico', 36: 'New York', 37: 'North Carolina', 38: 'North Dakota',\n",
    "             39: 'Ohio', 40: 'Oklahoma', 41: 'Oregon', 42: 'Pennsylvania',\n",
    "             44: 'Rhode Island', 45: 'South Carolina', 46: 'South Dakota', 47: 'Tennessee',\n",
    "             48: 'Texas', 49: 'Utah', 50: 'Vermont', 51: 'Virginia', 53: 'Washington',\n",
    "             54: 'West Virginia', 55: 'Wisconsin', 56: 'Wyoming', 66:'Guam', 72:'Puerto Rico'}\n",
    "\n",
    "# Reset the index of the dataframe to make '_STATE' a regular column\n",
    "df_map_usa = df_map_usa.reset_index()\n",
    "\n",
    "# Use the map method to replace the values in the '_STATE' column\n",
    "df_map_usa['_STATE'] = df_map_usa['_STATE'].map(state_map)\n",
    "df_map_usa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d00b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map_usa.to_csv('MapUSAFinal.csv', sep=\",\", index=False) #exporting the file to import it to Tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd30178",
   "metadata": {},
   "source": [
    "### Correlation matrix (General overview of potential correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bennet's code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddaf3c0",
   "metadata": {},
   "source": [
    "### Per-class feature histograms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d4c5e",
   "metadata": {},
   "source": [
    "Plotting the distribution of all features in their respective class (heart attack/disease: yes/no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d35b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devide target variable into their respective classes\n",
    "yes_data = df[df['_MICHD'] == 1]\n",
    "no_data = df[df['_MICHD'] == 2]\n",
    "\n",
    "features = [feature for feature in df.columns if feature != '_MICHD']\n",
    "\n",
    "# Calculate the number of rows and columns for subplots\n",
    "n_cols = 3\n",
    "n_rows = math.ceil(len(features) / n_cols)\n",
    "\n",
    "# Create a single figure with subplots\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(15, n_rows * 5))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "# Iterate through features and axes to create subplots\n",
    "for feature, ax in zip(features, axes.flatten()):\n",
    "    sns.histplot(yes_data[feature], color='#1f77b4', label='yes', alpha=0.5, stat='density', ax=ax)\n",
    "    sns.histplot(no_data[feature], color='#ff7f0e', label='no', alpha=0.5, stat='density', ax=ax)\n",
    "    ax.legend(title='Heart Disease')\n",
    "    ax.set_title(f'Distribution of {feature} by heart disease')\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Density')\n",
    "    \n",
    "# Save the figure to disk and close it to free up memory\n",
    "fig.savefig('Per-classHistALL.png', dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ff13b",
   "metadata": {},
   "source": [
    "After carefully inspecting the different per-class histogramns for all 121 features, we have selected a couple interesting to be displayed in greater detail.\n",
    "Therefore we need to change some of the scales of the features and remove some of the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a18b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = df[['WTKG3','_BMI5','_AGEG5YR','_VEGESUM','MAXVO2_','_FRUTSUM','_MICHD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f654a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the scale of WTKG3\n",
    "df['WTKG3'] = df['WTKG3'] / 100\n",
    "\n",
    "# Changing the scale of _BMI5\n",
    "df['_BMI5'] = df['_BMI5'] / 100\n",
    "\n",
    "# Changing the scale of _VEGESUM\n",
    "df['_VEGESUM'] = df['_VEGESUM'] / 100\n",
    "\n",
    "# Changing the scale of MAXVO2_\n",
    "df['MAXVO2_'] = df['MAXVO2_'] / 100\n",
    "df['MAXVO2_'] = df['MAXVO2_'].replace({999:0})\n",
    "\n",
    "# Changing the scale of _FRUTSUM\n",
    "df['_FRUTSUM'] = df['_FRUTSUM'] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['_BMI5'] = df['_BMI5'][(np.abs(stats.zscore(df['_BMI5'])) < 3)] #Removing values outside 3 stds (99% incl)\n",
    "df['_VEGESUM'] = df['_VEGESUM'][(np.abs(stats.zscore(df['_VEGESUM'])) < 3)] #Removing values outside 3 stds (99% incl)\n",
    "df['_FRUTSUM'] = df['_FRUTSUM'][(np.abs(stats.zscore(df['_FRUTSUM'])) < 3)] #Removing values outside 3 stds (99% incl)\n",
    "df['WTKG3'] = df['WTKG3'][(np.abs(stats.zscore(df['WTKG3'])) < 3)] #Removing values outside 3 stds (99% incl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da21d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redefining the features  \n",
    "features = [feature for feature in new_features if feature != '_MICHD']\n",
    "\n",
    "# Calculate the number of rows and columns for subplots\n",
    "n_cols = 3\n",
    "n_rows = math.ceil(len(features) / n_cols)\n",
    "\n",
    "# Create a single figure with subplots\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(15, n_rows * 5))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "# Iterate through features and axes to create subplots\n",
    "for feature, ax in zip(features, axes.flatten()):\n",
    "    sns.histplot(yes_data[feature], color='#1f77b4', label='yes', alpha=0.5, stat='density', ax=ax)\n",
    "    sns.histplot(no_data[feature], color='#ff7f0e', label='no', alpha=0.5, stat='density', ax=ax)\n",
    "    ax.set_title(f'Distribution of {feature} by heart disease')\n",
    "    ax.set_xlabel(feature)\n",
    "    \n",
    "# Create a custom legend for the entire figure\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='#1f77b4', alpha=0.5, label='Yes'),\n",
    "                   Patch(facecolor='#ff7f0e', alpha=0.5, label='No')]\n",
    "\n",
    "# Adjust the location and font size of the legend\n",
    "fig.legend(handles=legend_elements, title='Heart Disease', fontsize='large')\n",
    "\n",
    "# Save the figure to disk and close it to free up memory\n",
    "fig.savefig('Per-classHist.png', dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reiterate through features and axes to create subplots but now for instances instead of density\n",
    "for feature, ax in zip(features, axes.flatten()):\n",
    "    sns.histplot(yes_data[feature], color='#1f77b4', label='yes', alpha=0.5, ax=ax)\n",
    "    sns.histplot(no_data[feature], color='#ff7f0e', label='no', alpha=0.5, ax=ax)\n",
    "    ax.set_title(f'Distribution of {feature} by heart disease')\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Instances')\n",
    "    \n",
    "    \n",
    "# Create a custom legend for the entire figure\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='#1f77b4', alpha=0.5, label='Yes'),\n",
    "                   Patch(facecolor='#ff7f0e', alpha=0.5, label='No')]\n",
    "\n",
    "# Adjust the location and font size of the legend\n",
    "fig.legend(handles=legend_elements, title='Heart Disease', fontsize='large')\n",
    "    \n",
    "# Save the figure to disk and close it to free up memory\n",
    "fig.savefig('Per-classHist(Instances).png', dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5610cc31",
   "metadata": {},
   "source": [
    "## Apendix:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91af7626",
   "metadata": {},
   "source": [
    "### Color palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec868f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "sns.color_palette() # color palette "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30607a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sns.color_palette().as_hex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
