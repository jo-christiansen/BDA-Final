{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "286c922a",
   "metadata": {},
   "source": [
    "## Applying machine learning models to our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c7d381",
   "metadata": {},
   "source": [
    "Before we start with any ML or even evaluating those models we need to be aware of our baseline. How far is guessing going to get us? Over 20.5 million or 7.2% of adults in the United States aged 20 and older have had a CAD alone (CDC, 2022). Our specific baseline comes down to 90.19% of accuracy by guessing nobody has a heart attack (because our target values includes multiple kinds of heart attack). Meaning that 9.81% of the survey's participants have had any kind of heart attack. In order for our models to be any helpful we need a accuracy greater than 90.19%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7fde0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0dc60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing cleaned dataset\n",
    "pd.set_option(\"display.max_columns\", 125)\n",
    "df = pd.read_csv('Datasets/CleanedData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d9b843",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11798dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate Dataset in X and y\n",
    "X = df.drop('_MICHD', axis=1)\n",
    "y = df['_MICHD']\n",
    "\n",
    "# train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790e27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1165984",
   "metadata": {},
   "source": [
    "### K-nearest neighboor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4fc691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f3e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN model default\n",
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "\n",
    "print('The accuracy of the KNN model on the training data is {:.4f}'.format(knn.score(X_train, y_train)))\n",
    "print('The accuracy of the KNN model on the test data is {:.4f}'.format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab75ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop for perfect k\n",
    "for i in range(100)\n",
    "    knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "    \n",
    "    train_pred = knn.predict(X_train)\n",
    "    test_pred = knn.predict(X_test)\n",
    "    \n",
    "    print(\"k=\", k, \"Train Accuracy:\", accuracy_score(y_train, train_pred))\n",
    "    print(\"k=\", k, \"Test Accuracy:\", accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952fa02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN optimal\n",
    "knn_optimal = KNeighborsClassifier(n_neighbors=65) \n",
    "\n",
    "print('The accuracy of the KNN model on the training data is {:.4f}'.format(knn.score(X_train, y_train)))\n",
    "print('The accuracy of the KNN model on the test data is {:.4f}'.format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b381a6b7",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d5e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9cab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "print('The accuracy of the LogisticRegression model on the training data is {:.4f}'.format(logisticRegr.score(X_train,y_train)))\n",
    "print('The accuracy of the LogisticRegression model on the test data is {:.4f}'.format(logisticRegr.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c49305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter \n",
    "penalty_options = ['l1', 'l2', 'elasticnet']\n",
    "solver_options = ['lbfgs', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "C_values = [0.1, 1, 5, 10]\n",
    "iter_values = [100, 1000]\n",
    "\n",
    "# Create a grid\n",
    "param_grid = dict(penalty=penalty_options, C=C_values, solver=solver_options, max_iter=iter_values)\n",
    "\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "\n",
    "grid.fit(X_train_std, y_train)\n",
    "\n",
    "# Check the results\n",
    "print(grid.cv_results_)\n",
    "print('\\n')\n",
    "print(grid.best_score_)\n",
    "print('\\n')\n",
    "print(grid.best_params_)\n",
    "print('\\n')\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349fdfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the scaled data\n",
    "logisticRegr = LogisticRegression(penalty='l1',C=1,solver='saga',max_iter=1000, n_jobs=-1).fit(X_train_std, y_train)\n",
    "\n",
    "print('The accuracy of the fine-tuned LogisticRegression model on the scaled training data is {:.4f}'.format(logisticRegr.score(X_train_std, \n",
    "                                                                                                                                y_train)))\n",
    "print('The accuracy of the fine-tuned LogisticRegression model on the scaled test data is {:.4f}'.format(logisticRegr.score(X_test_std, \n",
    "                                                                                                                            y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0fd3bf",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d7c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d730c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.4f}\".format(clf.score(X_train, y_train))) \n",
    "print(\"Accuracy on test set: {:.4f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504bfc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to try all combinations \n",
    "smoothing_values = [25, 22.5, 20, 10, 5, 2, 1, 0.5, 0.1, 0.01, 1e-3, 1e-6, 1e-9, 1e-12]\n",
    "\n",
    "for s in smoothing_values:\n",
    "    # Create and train the GaussianNB\n",
    "    clf = GaussianNB(var_smoothing=s).fit(X_train_std, y_train)\n",
    "\n",
    "    print('var_smoothing: {}, train accuracy: {:.4f}, test accuracy: {:.4f}'.format(s, clf.score(X_train_std, y_train),clf.score(X_test_std, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655fc760",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB(var_smoothing=20).fit(X_train_std, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.4f}\".format(clf.score(X_train_std, y_train))) \n",
    "print(\"Accuracy on test set: {:.4f}\".format(clf.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632604f3",
   "metadata": {},
   "source": [
    "### Support vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df03dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4780d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC().fit(X_train, y_train)\n",
    "\n",
    "# Accuracy of the model with out scaling and fine-tuning\n",
    "print(\"Accuracy on training set: {:.4f}\".format(svc.score(X_train, y_train))) \n",
    "print(\"Accuracy on test set: {:.4f}\".format(svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb3497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "kernel_options = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "C_values = [0.1, 1, 5, 10]\n",
    "gamma_values = ['auto', 'scale']\n",
    "\n",
    "# Creating grid\n",
    "param_grid = dict(kernel=kernel_options, C=C_values, gamma=gamma_values)\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "\n",
    "grid.fit(X_train_std, y_train)\n",
    "\n",
    "# Results\n",
    "print(grid.cv_results_)\n",
    "print('\\n')\n",
    "print(grid.best_score_)\n",
    "print('\\n')\n",
    "print(grid.best_params_)\n",
    "print('\\n')\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d059d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=2.65, gamma='scale', kernel='rbf').fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.4f}\".format(svc.score(X_train, y_train))) \n",
    "print(\"Accuracy on test set: {:.4f}\".format(svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877f520",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e11c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ea844",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.4f}\".format(dtree.score(X_train, y_train))) \n",
    "print(\"Accuracy on test set: {:.4f}\".format(dtree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff26043",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth=6, random_state=0).fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.4f}\".format(dtree.score(X_train, y_train))) \n",
    "print(\"Accuracy on test set: {:.4f}\".format(dtree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf6f10",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f2c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cb509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=42).fit(X_train, y_train)\n",
    "print(\"Accuracy on training set: {:.4f}\".format(rand_forest.score(X_train, y_train))) \n",
    "print(\"Accuracy on test set: {:.4f}\".format(rand_forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718059d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = [2, 5, 7, 10, 12, 15, 20]\n",
    "f_values = [7, 9, 11, 13, 15, 17]\n",
    "d_values = [2, 4, 6, 8, 10]\n",
    "\n",
    "# 3 for loops\n",
    "for n in n_values:\n",
    "\n",
    "    for f in f_values:\n",
    "        \n",
    "        for d in d_values:\n",
    "    \n",
    "            forest = RandomForestClassifier(n_estimators=n, random_state=42, n_jobs=-1, max_features=f, max_depth=d).fit(X_train, y_train)\n",
    "\n",
    "            print(\"n=\", n, \", f=\", f, \"d=\", d, \"Accuracy on training set: {:.4f}\".format(forest.score(X_train, y_train))) \n",
    "            print(\"n=\", n, \", f=\", f, \"d=\", d, \"Accuracy on test set: {:.4f}\".format(forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5152d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(n_estimators=12, random_state=42, n_jobs=-1, max_features=11, max_depth=10).fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.4f}\".format(rand_forest.score(X_train, y_train))) \n",
    "print(\"Accuracy on test set: {:.4f}\".format(rand_forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ff77d7",
   "metadata": {},
   "source": [
    "### Gradient boosted regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf39332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8423206",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingClassifier(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.4f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.4f}\".format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98f8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "learning_options = [0.001, 0.01, 0.1, 0.25, 0.5, 1]\n",
    "Depth_options = [1, 2, 3, 5, 7]\n",
    "random = [0]\n",
    "n_est = [75, 100, 150, 200, 350, 500]\n",
    "\n",
    "# Create grid\n",
    "param_grid = dict(learning_rate=learning_options, max_depth=Depth_options, random_state=random, n_estimators=n_est)\n",
    "\n",
    "\n",
    "grid = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=3, scoring='accuracy').fit(X_train, y_train)\n",
    "\n",
    "# results\n",
    "print(grid.cv_results_)\n",
    "print('\\n')\n",
    "print(grid.best_score_)\n",
    "print('\\n')\n",
    "print(grid.best_params_)\n",
    "print('\\n')\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707fd818",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingClassifier(random_state=0,learning_rate=0.1,max_depth=3,n_estimators=100).fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.4f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.4f}\".format(gbrt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dd3072",
   "metadata": {},
   "source": [
    "### Gradient boosted trees using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e097a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b118cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost expects binary values [0 1] from the y \n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b41e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cl = xgb.XGBClassifier().fit(X_train,y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.4f}\".format(xg_cl.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.4f}\".format(xg_cl.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93858569",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators = 20, max_depth=5, eta=0.30, seed = 123).fit(X_train,y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.6f}\".format(xg_cl.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.6f}\".format(xg_cl.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
